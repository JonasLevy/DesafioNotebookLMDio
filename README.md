
Este trabalho foi desenvolvido como parte de um desafio do bootcamp **DIO – Bradesco: GenAI & Dados**, que propôs a criação de uma pesquisa utilizando a ferramenta NotebookLM, com base em múltiplas fontes de informação. O tema escolhido foi a arquitetura Transformer, apresentada no artigo *“Attention Is All You Need”* (2017), devido à sua relevância para o avanço da Inteligência Artificial e da IA generativa.

A pesquisa utiliza diferentes fontes para contextualizar a evolução do processamento de linguagem natural, destacando as limitações dos modelos anteriores e as inovações introduzidas pelos Transformers, especialmente o mecanismo de atenção. Dessa forma, o trabalho evidencia a importância dessa arquitetura como base das principais aplicações atuais de IA generativa e demonstra como o uso do NotebookLM contribui para a organização e análise de conteúdos técnicos.

**NotebookLM da pesquisa:**  
https://notebooklm.google.com/notebook/1d330bd3-b89d-45c1-862f-7c65c7f82388
